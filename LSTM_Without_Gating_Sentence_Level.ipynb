{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Models without gating",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/notmanan/Depression-Detection-Through-Multi-Modal-Data/blob/master/Models_without_gating.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4i5eg6FCkT_",
        "colab_type": "code",
        "outputId": "b3faa2ca-2ca4-40cf-eaef-9f24ffd329e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf6Sky1CD-iX",
        "colab_type": "text"
      },
      "source": [
        "Data Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EmOAYuXD_2x",
        "colab_type": "code",
        "outputId": "fd4eb831-c69b-4cef-8839-bb56546ff300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "import gc\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import math\n",
        "\n",
        "from smart_open import open\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.layers import Dropout\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "import gc\n",
        "import math\n",
        "dev_location = \"dev_data\"\n",
        "test_location = \"test_data\"\n",
        "train_location = \"train_data\"\n",
        "\n",
        "devData = np.array(pd.read_csv('/content/drive/My Drive/MCA Dataset/dev_split_Depression_AVEC2017.csv',delimiter=',',encoding='utf-8'))[:, 0:2]\n",
        "testData = np.array(pd.read_csv('/content/drive/My Drive/MCA Dataset/full_test_split.csv',delimiter=',',encoding='utf-8'))[:, 0:2]\n",
        "trainData = np.array(pd.read_csv('/content/drive/My Drive/MCA Dataset/train_split_Depression_AVEC2017.csv',delimiter=',',encoding='utf-8'))[:, 0:2]\n",
        "\n",
        "\n",
        "dataset = np.concatenate((devData, np.concatenate((testData, trainData))))\n",
        "\n",
        "gc.collect()      \n",
        "max_num_words = 17\n",
        "model = KeyedVectors.load_word2vec_format('/content/drive/My Drive/MCA Dataset/Copy of GoogleNews-vectors-negative300.bin', binary=True)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "\n",
        "def checkDataPointExistence(patientID, split):\n",
        "  for i in split:\n",
        "    if(patientID == i[0]):\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "def getData(patientID, location):\n",
        "  # print(\"PatientID: \" + str(int(patientID)))\n",
        "  retData = [int(patientID)]\n",
        "  textD = getTextData(patientID, location)\n",
        "  audioD = getAudioData(patientID, location, textD)\n",
        "  videoD = getVideoData(str(int(patientID)), location, textD)\n",
        "  # patientD = np.concatenate((textD, audioD, videoD), axis = 1)\n",
        "  # print(\"Final Patient Data: \" + str(patientD.shape))\n",
        "  return textD,audioD,videoD\n",
        "\n",
        "def getTextData(patientID, location):\n",
        "  fileName = \"/content/drive/My Drive/MCA Dataset/\"+ str(location) + \"/\" + str(int(patientID)) + \"_TRANSCRIPT.csv\"\n",
        "  file = np.array(pd.read_csv(fileName,delimiter='\\t',encoding='utf-8', engine='python'))\n",
        "\n",
        "  # Remove All Utterences By Ellie:\n",
        "  for i in range(len(file)):\n",
        "    if(file[i][2] != 'Participant'):\n",
        "      np.delete(file, i)\n",
        "      i-=1\n",
        "\n",
        "  # Remove Speaker Columnn\n",
        "  file = np.delete(file, 2, 1)\n",
        "  \n",
        "  # Convert Text Into Word Vectors:\n",
        "  w2vs = np.zeros((1, max_num_words*300))\n",
        "  for i in range(len(file)):\n",
        "    sentence = file[i][2]\n",
        "    w2v = returnWordToVec(sentence)\n",
        "    w2vs = np.concatenate((w2vs, w2v), axis = 0)\n",
        "  w2vs = np.delete(w2vs, 0, 0)  \n",
        "\n",
        "  # Delete Sentences and Replace With W2Vs\n",
        "  file = np.delete(file, 2, 1)\n",
        "  file = np.concatenate((file, w2vs), axis = 1)\n",
        "  return file\n",
        "\n",
        "def remove_StopWords(sentence):\n",
        "    filtered_sentence = [] \n",
        "    for w in sentence: \n",
        "        if w not in stop_words: \n",
        "            filtered_sentence.append(w)\n",
        "    return filtered_sentence\n",
        "\n",
        "def returnWordToVec(sentence):\n",
        "  global max_num_words, stop_words, model\n",
        "  sentence = str(sentence).split(\" \")\n",
        "  sentence = remove_StopWords(sentence)\n",
        "  index_word = 0\n",
        "  wordMatrix = np.zeros(max_num_words*300)\n",
        "  for j in range(min(max_num_words, len(sentence))):\n",
        "    try:\n",
        "      word = sentence[j]\n",
        "      if(word[0] == '<'):\n",
        "        if(word.find('>')!=-1):\n",
        "          word = word[1:-1]\n",
        "        else:\n",
        "          word = word[1:]\n",
        "      else:\n",
        "        if(word.find('>')!=-1):\n",
        "          word = word[0:-1]\n",
        "      ss = np.array(model[word])\n",
        "      wordMatrix[index_word*300:(index_word+1)*300] = ss\n",
        "      index_word+=1\n",
        "    except Exception as e:\n",
        "      continue\n",
        "  wordMatrix = np.array(wordMatrix.reshape(1,-1))\n",
        "  return wordMatrix\n",
        "\n",
        "def audioDataHelper(X):\n",
        "    for i in range(X.shape[0]):\n",
        "        if(X[i,1] == 0):\n",
        "            X[i,0] = 0\n",
        "            for j in range(7):\n",
        "                X[i,j+1] = 0\n",
        "    X = np.array(X)\n",
        "    return X\n",
        "    \n",
        "def getAudioData(patientID, location, textD):\n",
        "  fileName = \"/content/drive/My Drive/MCA Dataset/\"+ str(location) + \"/\" + str(int(patientID)) + \"_COVAREP.csv\"\n",
        "  data = pd.read_csv(fileName,header = None)\n",
        "  data = data.iloc[:,:].values\n",
        "  data = audioDataHelper(data)\n",
        "  # print(\"Audio Raw Data:\" + str(data.shape))\n",
        "  sentenceDatas = []\n",
        "  for sentence in textD:\n",
        "    sentenceStartime = sentence[0]\n",
        "    sentenceEndTime = sentence[1]\n",
        "    startIndex = math.floor(sentenceStartime/0.01)\n",
        "    endIndex = math.ceil(sentenceEndTime/0.01)\n",
        "    # print(\"Start Time: \" + str(startIndex))\n",
        "    # print(\"End Time: \" + str(endIndex))\n",
        "    sentenceData = data[startIndex: endIndex]\n",
        "    sentenceData = np.average(sentenceData, axis = 0)\n",
        "    # This might be a possible error\n",
        "    sentenceData = np.array(sentenceData.reshape(1, -1))\n",
        "    sentenceDatas.append(sentenceData)\n",
        "  \n",
        "  sentenceDatas = np.array(sentenceDatas)\n",
        "  sentenceDatas = np.reshape(sentenceDatas, (textD.shape[0],-1))\n",
        "  # print(\"Audio Final Data:\" + str(sentenceDatas.shape))\n",
        "\n",
        "  return sentenceDatas\n",
        "\n",
        "def getVideoDataHelper(patientID, location):\n",
        "  root = \"/content/drive/My Drive/MCA Dataset/\"+ str(location) + \"/\" \n",
        "  file1 = root + (patientID)+\"_CLNF_AUs.txt\"\n",
        "  file2 = root + (patientID)+\"_CLNF_features.txt\"\n",
        "  file3 = root + (patientID)+\"_CLNF_features3D.txt\"\n",
        "  file4 = root + (patientID)+\"_CLNF_gaze.txt\"\n",
        "  file5 = root + (patientID)+\"_CLNF_hog.txt\"\n",
        "  file6 = root + (patientID)+\"_CLNF_pose.txt\"\n",
        "  data = processVideoData(file1)\n",
        "  data = np.concatenate((data, processVideoData(file2)), 1)\n",
        "  data = np.concatenate((data, processVideoData(file3)), 1)\n",
        "  data = np.concatenate((data, processVideoData(file4)), 1)\n",
        "  data = np.concatenate((data, processVideoData(file6)), 1)\n",
        "  # print(\"Video Raw Data:\" + str(data.shape))\n",
        "  return data\n",
        "\n",
        "def processVideoData(filename):\n",
        "  try:\n",
        "    data = pd.read_csv(filename,delimiter=',', dtype=float)\n",
        "    X = data.iloc[:,:].values\n",
        "    X = np.delete(X, 0, 1)\n",
        "    X = np.delete(X, 1, 1)\n",
        "  except:\n",
        "    # print(\"Video Data corrupt, fixing.\")\n",
        "    data = pd.read_csv(filename,delimiter=',')\n",
        "    X = data.iloc[:,:].values\n",
        "    X = np.delete(X, 0, 1)\n",
        "    X = np.delete(X, 1, 1)\n",
        "    for i in range(len(X)):\n",
        "        if(isinstance(X[i][5],str) or isinstance(X[i][7],str)):\n",
        "            X[i] = np.zeros((1, X.shape[1]))\n",
        "            # print(\"se\" , end = \" \")    \n",
        "  return X\n",
        "\n",
        "def getVideoData(patientID, location, textD):\n",
        "  data = getVideoDataHelper(patientID, location)\n",
        "  sentenceDatas = []\n",
        "  for sentence in textD:\n",
        "    sentenceStartime = sentence[0]\n",
        "    sentenceEndTime = sentence[1]\n",
        "    startIndex = math.floor(sentenceStartime/0.333)\n",
        "    endIndex = math.ceil(sentenceEndTime/0.333)\n",
        "    # print(\"Start Time: \" + str(startIndex))\n",
        "    sentenceData = data[startIndex: endIndex]\n",
        "    sentenceData = np.average(sentenceData, axis = 0)\n",
        "    # This might be a possible error\n",
        "    sentenceData = np.array(sentenceData.reshape(1, -1))\n",
        "    sentenceDatas.append(sentenceData)\n",
        "  \n",
        "  sentenceDatas = np.array(sentenceDatas)\n",
        "  sentenceDatas = np.reshape(sentenceDatas, (textD.shape[0],-1))\n",
        "  # print(\"Video Final Data:\" + str(sentenceDatas.shape))\n",
        "  return sentenceDatas\n",
        "\n",
        "# Xtrain = []\n",
        "Ytrain = []\n",
        "# Xtest = []\n",
        "Ytest = []\n",
        "\n",
        "\n",
        "audio_train = []\n",
        "video_train = []\n",
        "text_train = []\n",
        "\n",
        "audio_test = []\n",
        "video_test = []\n",
        "text_test = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for datapoint in dataset:\n",
        "  # print(datapoint[0])\n",
        "  if(checkDataPointExistence(datapoint[0], devData)):\n",
        "\n",
        "    # Data Point in Dev Set\n",
        "    text,audio,video = getData(datapoint[0], dev_location)\n",
        "    audio_train.append(audio)\n",
        "    video_train.append(video)\n",
        "    text_train.append(text)\n",
        "    # Xtest.append(data)\n",
        "    Ytrain.append(datapoint[1])\n",
        "    # print(data)\n",
        "  elif(checkDataPointExistence(datapoint[0], testData)):\n",
        "    # Data Point in Test Set\n",
        "    text,audio,video = getData(datapoint[0], test_location)\n",
        "    audio_test.append(audio)\n",
        "    video_test.append(video)\n",
        "    text_test.append(text)\n",
        "    # Xtest.append(data)\n",
        "    Ytest.append(datapoint[1])\n",
        "  elif(checkDataPointExistence(datapoint[0], trainData)):\n",
        "    # Data Point in Train Set\n",
        "    text,audio,video = getData(datapoint[0], train_location)\n",
        "    audio_train.append(audio)\n",
        "    video_train.append(video)\n",
        "    text_train.append(text)\n",
        "    # Xtest.append(data)\n",
        "    Ytrain.append(datapoint[1])\n",
        "\n",
        "def refactor(arr, size):\n",
        "  arrsize = arr.shape[0]\n",
        "  temp = np.zeros((size, arr.shape[1]))\n",
        "  for i in range(min(len(arr), size)):\n",
        "    temp[i] = arr[i]\n",
        "  return temp\n",
        "\n",
        "numberOfSentences = 250\n",
        "\n",
        "devData = []\n",
        "trainData = []\n",
        "testData = []\n",
        "gc.collect()\n",
        "\n",
        "for i in range(len(audio_train)):\n",
        "  audio_train[i] = refactor(audio_train[i], numberOfSentences)\n",
        "  video_train[i] = refactor(video_train[i], numberOfSentences)\n",
        "  text_train[i] = refactor(text_train[i], numberOfSentences)\n",
        "  # print(Xtrain[i].shape)\n",
        "\n",
        "# for i in range(len(audio_dev)):\n",
        "#   audio_dev[i] = refactor(audio_dev[i], numberOfSentences)\n",
        "#   video_dev[i] = refactor(video_dev[i], numberOfSentences)\n",
        "#   text_dev[i] = refactor(text_dev[i], numberOfSentences)\n",
        "#   # print(Xtrain[i].shape)\n",
        "\n",
        "for i in range(len(audio_test)):\n",
        "  audio_test[i] = refactor(audio_train[i], numberOfSentences)\n",
        "  video_test[i] = refactor(video_train[i], numberOfSentences)\n",
        "  text_test[i] = refactor(text_train[i], numberOfSentences)\n",
        "  # print(Xtest[i].shape)\n",
        "audio_test = np.array(audio_test)\n",
        "video_test = np.array(video_test)\n",
        "text_test = np.array(text_test)\n",
        "text_test = text_test[:,:,2:]\n",
        "\n",
        "audio_train = np.array(audio_train)\n",
        "video_train = np.array(video_train)\n",
        "text_train = np.array(text_train)\n",
        "text_train = text_train[:,:,2:]\n",
        "\n",
        "# audio_dev = np.array(audio_dev)\n",
        "# video_dev = np.array(video_dev)\n",
        "# text_dev = np.array(text_dev)\n",
        "# text_dev = text_dev[:,:,2:]\n",
        "\n",
        "dataset = []\n",
        "gc.collect()\n",
        "\n",
        "print(audio_test.shape,video_test.shape,text_test.shape)\n",
        "print(audio_train.shape,video_train.shape,text_train.shape)\n",
        "# print(audio_dev.shape,video_dev.shape,text_dev.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: DtypeWarning: Columns (4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: DtypeWarning: Columns (4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
            "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(41, 250, 74) (41, 250, 388) (41, 250, 5100)\n",
            "(137, 250, 74) (137, 250, 388) (137, 250, 5100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUGdf5rEQURQ",
        "colab_type": "code",
        "outputId": "753d407d-fc09-49cc-9f0c-d9b3d92a0f23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "Ytrain = np.array(Ytrain)\n",
        "Ytest = np.array(Ytest)\n",
        "\n",
        "\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "def upsample(X_train,Y_train):\n",
        "  X_train_0 = X_train[Y_train==0]\n",
        "  X_train_1 = X_train[Y_train==1]\n",
        "\n",
        "  Y_train_1 = Y_train[Y_train==1]\n",
        "  # print(Y_train_1.shape)\n",
        "  # print(X_train_1.shape)\n",
        "  size = X_train_0.shape[0] - X_train_1.shape[0]\n",
        "  X = []\n",
        "  Y = []\n",
        "  X_train = list(X_train)\n",
        "  Y_train = list(Y_train)\n",
        "  while(size>0):\n",
        "    size -= 1\n",
        "    index = np.random.randint(0,X_train_1.shape[0]-1)\n",
        "    leave_index = np.random.randint(0,len(X_train)-1)\n",
        "    X_add = X_train_1[index]\n",
        "    X_leave = X_train[leave_index]\n",
        "\n",
        "    Y_add = Y_train_1[index]\n",
        "    Y_leave = Y_train[leave_index]\n",
        "\n",
        "    X_train[leave_index] = X_add\n",
        "    X_train.append(X_leave)\n",
        "\n",
        "    Y_train[leave_index] = Y_add\n",
        "    Y_train.append(Y_leave)\n",
        "\n",
        "\n",
        "  X_train = np.array(X_train)\n",
        "  Y_train = np.array(Y_train)\n",
        "  return X_train,Y_train\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "audio_train = np.nan_to_num(audio_train)\n",
        "video_train = np.nan_to_num(video_train)\n",
        "text_train = np.nan_to_num(text_train)\n",
        "\n",
        "audio_train, _ = upsample(audio_train,Ytrain)\n",
        "video_train, _ = upsample(video_train,Ytrain)\n",
        "text_train, Ytrain = upsample(text_train,Ytrain)\n",
        "\n",
        "print(audio_train.shape)\n",
        "print(video_train.shape)\n",
        "print(text_train.shape)\n",
        "print(Ytrain.shape)\n",
        "\n",
        "for i in range(audio_train.shape[0]):\n",
        "  audio_train[i] = sklearn.preprocessing.normalize(audio_train[i])\n",
        "  video_train[i] = sklearn.preprocessing.normalize(video_train[i])\n",
        "  text_train[i] = sklearn.preprocessing.normalize(text_train[i])\n",
        "\n",
        "\n",
        "print(Ytest.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(196, 250, 74)\n",
            "(196, 250, 388)\n",
            "(196, 250, 5100)\n",
            "(196,)\n",
            "(41,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th9L4TBzGTHJ",
        "colab_type": "code",
        "outputId": "a980d913-d99b-4631-de8d-79d7ade7caf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Text\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class Highway(layers.Layer):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Highway, self).__init__()\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    n_sentences = input_shape[1]\n",
        "    n_features = input_shape[2]\n",
        "    carry_bias = keras.initializers.Constant(value=-1.0)\n",
        "    random_dist = keras.initializers.RandomNormal(mean=0.0, stddev=0.1)\n",
        "\n",
        "    carry_bias_2 = keras.initializers.Constant(value= 0.1)\n",
        "\n",
        "    self.W_T = self.add_weight(shape=(n_features, n_features),initializer = random_dist,trainable=True)\n",
        "    self.b_T = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias, trainable=True)\n",
        "    # self.W_T = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1),trainable=True)\n",
        "    # self.b_T = tf.Variable(tf.constant(-1.0, shape=[n_data_points, n_sentences, n_features]),trainable=True)\n",
        "   \n",
        "    self.W = self.add_weight(shape=( n_features, n_features),initializer = random_dist, trainable=True)\n",
        "    self.b = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias_2, trainable=True)\n",
        "    # self.W = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1), trainable=True)\n",
        "    # self.b = tf.Variable(tf.constant(0.1, shape=[n_data_points, n_sentences, n_features]), trainable=True)  \n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = inputs\n",
        "    T = tf.sigmoid(tf.matmul(x, self.W_T) + self.b_T, name=\"transform_gate\")\n",
        "    H = tf.nn.relu(tf.matmul(x, self.W) + self.b, name=\"activation\")\n",
        "    C = tf.subtract(1.0, T, name=\"carry_gate\")\n",
        "    \n",
        "    return tf.add(tf.multiply(H, T), tf.multiply(x, C), \"y\")\n",
        "\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "# audio_dev = np.nan_to_num(audio_dev)\n",
        "# video_dev = np.nan_to_num(video_dev)\n",
        "# text_dev = np.nan_to_num(text_dev)\n",
        "\n",
        "\n",
        "# for i in range(audio_dev.shape[0]):\n",
        "#   audio_dev[i] = sklearn.preprocessing.normalize(audio_dev[i])\n",
        "#   video_dev[i] = sklearn.preprocessing.normalize(video_dev[i])\n",
        "#   text_dev[i] = sklearn.preprocessing.normalize(text_dev[i])\n",
        "\n",
        "audio_test = np.nan_to_num(audio_test)\n",
        "video_test = np.nan_to_num(video_test)\n",
        "text_test = np.nan_to_num(text_test)\n",
        "\n",
        "import sklearn\n",
        "\n",
        "for i in range(audio_test.shape[0]):\n",
        "  audio_test[i] = sklearn.preprocessing.normalize(audio_test[i])\n",
        "  video_test[i] = sklearn.preprocessing.normalize(video_test[i])\n",
        "  text_test[i] = sklearn.preprocessing.normalize(text_test[i])\n",
        "\n",
        "#LSTM FOR TEXT \n",
        "# first input model\n",
        "\n",
        "input3 = Input(shape = (250,5100))\n",
        "dense4 = Dense(1000)(input3)\n",
        "dense5 = Dense(500)(dense4)\n",
        "dense6 = Dense(250)(dense5)\n",
        "# interpretation model\n",
        "lstm = LSTM(128, dropout = 0.2, recurrent_dropout = 0.2)(dense6)\n",
        "output = Dense(1, activation='sigmoid')(lstm)\n",
        "model = Model(inputs=input3, outputs=output)\n",
        "# summarize layers\n",
        "print(model.summary())\n",
        "# plot graph\n",
        "print(plot_model(model, to_file='multiple_inputs.png'))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate= 0.001)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
        "\n",
        "model.fit(text_train,Ytrain, epochs=50,validation_split = 0.2, callbacks = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=20, verbose=0, mode='min',\n",
        "    baseline=None, restore_best_weights=True), batch_size = 137)\n",
        "\n",
        "text_test = np.nan_to_num(text_test)\n",
        "\n",
        "def Thresholding(Y_pred, threshold):\n",
        "  Y_pred2 = []\n",
        "  print(\"Y_pred: \", Y_pred.shape)\n",
        "  for i in range(len(Y_pred)):\n",
        "    if(Y_pred[i] < threshold):\n",
        "      Y_pred2.append(0)\n",
        "    else:\n",
        "      Y_pred2.append(1)\n",
        "\n",
        "  return np.array(Y_pred2)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "pred = model.predict(text_test)\n",
        "\n",
        "print(classification_report(Ytest,Thresholding(pred,0.5)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.6)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.4)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.3)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.7)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 250, 5100)]       0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 250, 1000)         5101000   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 250, 500)          500500    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 250, 250)          125250    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 128)               194048    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 5,920,927\n",
            "Trainable params: 5,920,927\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "<IPython.core.display.Image object>\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.7060 - val_loss: 0.6764\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6658 - val_loss: 0.6472\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6163 - val_loss: 0.5822\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.5536 - val_loss: 0.5143\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.5289 - val_loss: 0.5090\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.4899 - val_loss: 0.6518\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.4351 - val_loss: 0.6816\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.4533 - val_loss: 0.5920\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.4367 - val_loss: 0.5134\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3686 - val_loss: 0.4758\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.2908 - val_loss: 0.4786\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3806 - val_loss: 0.5297\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.2936 - val_loss: 0.5840\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3789 - val_loss: 0.6356\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3725 - val_loss: 0.6858\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3732 - val_loss: 0.7300\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3005 - val_loss: 0.7644\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3788 - val_loss: 0.7706\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3933 - val_loss: 0.6890\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3221 - val_loss: 0.6157\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3762 - val_loss: 0.6128\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.2702 - val_loss: 0.6463\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3072 - val_loss: 0.7495\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3099 - val_loss: 0.7272\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.2815 - val_loss: 0.7603\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.2700 - val_loss: 0.7748\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.2472 - val_loss: 0.9125\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.5627 - val_loss: 0.8755\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3153 - val_loss: 0.9764\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.4191 - val_loss: 0.6912\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.83      0.79        29\n",
            "         1.0       0.44      0.33      0.38        12\n",
            "\n",
            "    accuracy                           0.68        41\n",
            "   macro avg       0.60      0.58      0.58        41\n",
            "weighted avg       0.66      0.68      0.67        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.83      0.79        29\n",
            "         1.0       0.44      0.33      0.38        12\n",
            "\n",
            "    accuracy                           0.68        41\n",
            "   macro avg       0.60      0.58      0.58        41\n",
            "weighted avg       0.66      0.68      0.67        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      0.38      0.50        29\n",
            "         1.0       0.31      0.67      0.42        12\n",
            "\n",
            "    accuracy                           0.46        41\n",
            "   macro avg       0.52      0.52      0.46        41\n",
            "weighted avg       0.61      0.46      0.48        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.79      0.38      0.51        29\n",
            "         1.0       0.33      0.75      0.46        12\n",
            "\n",
            "    accuracy                           0.49        41\n",
            "   macro avg       0.56      0.56      0.49        41\n",
            "weighted avg       0.65      0.49      0.50        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.83      0.79        29\n",
            "         1.0       0.44      0.33      0.38        12\n",
            "\n",
            "    accuracy                           0.68        41\n",
            "   macro avg       0.60      0.58      0.58        41\n",
            "weighted avg       0.66      0.68      0.67        41\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9W8SEKzGqMd",
        "colab_type": "code",
        "outputId": "d20cf3f8-8b77-49eb-e2ff-5f3a637325bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Audio\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class Highway(layers.Layer):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Highway, self).__init__()\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    n_sentences = input_shape[1]\n",
        "    n_features = input_shape[2]\n",
        "    carry_bias = keras.initializers.Constant(value=-1.0)\n",
        "    random_dist = keras.initializers.RandomNormal(mean=0.0, stddev=0.1)\n",
        "\n",
        "    carry_bias_2 = keras.initializers.Constant(value= 0.1)\n",
        "\n",
        "    self.W_T = self.add_weight(shape=(n_features, n_features),initializer = random_dist,trainable=True)\n",
        "    self.b_T = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias, trainable=True)\n",
        "    # self.W_T = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1),trainable=True)\n",
        "    # self.b_T = tf.Variable(tf.constant(-1.0, shape=[n_data_points, n_sentences, n_features]),trainable=True)\n",
        "   \n",
        "    self.W = self.add_weight(shape=( n_features, n_features),initializer = random_dist, trainable=True)\n",
        "    self.b = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias_2, trainable=True)\n",
        "    # self.W = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1), trainable=True)\n",
        "    # self.b = tf.Variable(tf.constant(0.1, shape=[n_data_points, n_sentences, n_features]), trainable=True)  \n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = inputs\n",
        "    T = tf.sigmoid(tf.matmul(x, self.W_T) + self.b_T, name=\"transform_gate\")\n",
        "    H = tf.nn.relu(tf.matmul(x, self.W) + self.b, name=\"activation\")\n",
        "    C = tf.subtract(1.0, T, name=\"carry_gate\")\n",
        "    \n",
        "    return tf.add(tf.multiply(H, T), tf.multiply(x, C), \"y\")\n",
        "\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "#LSTM FOR AUDIO\n",
        "# first input model\n",
        "\n",
        "input3 = Input(shape = (250,74))\n",
        "# dense4 = Dense(1000)(input3)\n",
        "# dense5 = Dense(500)(dense4)\n",
        "# dense6 = Dense(250)(dense5)\n",
        "# interpretation model\n",
        "lstm = LSTM(60, dropout = 0.2, recurrent_dropout = 0.2)(input3)\n",
        "output = Dense(1, activation='sigmoid')(lstm)\n",
        "model = Model(inputs=input3, outputs=output)\n",
        "# summarize layers\n",
        "print(model.summary())\n",
        "# plot graph\n",
        "print(plot_model(model, to_file='multiple_inputs.png'))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0001)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
        "\n",
        "model.fit(audio_train,Ytrain, validation_split = 0.2, callbacks = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=30, verbose=0, mode='min',\n",
        "    baseline=None, restore_best_weights=True), epochs=50, batch_size = 137)\n",
        "\n",
        "audio_test = np.nan_to_num(audio_test)\n",
        "\n",
        "def Thresholding(Y_pred, threshold):\n",
        "  Y_pred2 = []\n",
        "  print(\"Y_pred: \", Y_pred.shape)\n",
        "  for i in range(len(Y_pred)):\n",
        "    if(Y_pred[i] < threshold):\n",
        "      Y_pred2.append(0)\n",
        "    else:\n",
        "      Y_pred2.append(1)\n",
        "\n",
        "  return np.array(Y_pred2)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "pred = model.predict(audio_test)\n",
        "\n",
        "print(classification_report(Ytest,Thresholding(pred,0.5)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.6)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.4)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.3)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.7)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 250, 74)]         0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 60)                32400     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 61        \n",
            "=================================================================\n",
            "Total params: 32,461\n",
            "Trainable params: 32,461\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "<IPython.core.display.Image object>\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 1s 266ms/step - loss: 0.6906 - val_loss: 0.6977\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 148ms/step - loss: 0.6942 - val_loss: 0.6980\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 148ms/step - loss: 0.6945 - val_loss: 0.6981\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 150ms/step - loss: 0.6954 - val_loss: 0.6981\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 153ms/step - loss: 0.6947 - val_loss: 0.6980\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 147ms/step - loss: 0.6937 - val_loss: 0.6979\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 151ms/step - loss: 0.6931 - val_loss: 0.6979\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 0.6916 - val_loss: 0.6979\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 191ms/step - loss: 0.6883 - val_loss: 0.6980\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 1s 294ms/step - loss: 0.6918 - val_loss: 0.6982\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 1s 251ms/step - loss: 0.6918 - val_loss: 0.6985\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 151ms/step - loss: 0.6926 - val_loss: 0.6988\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 152ms/step - loss: 0.6935 - val_loss: 0.6990\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 0s 154ms/step - loss: 0.6952 - val_loss: 0.6991\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 152ms/step - loss: 0.6973 - val_loss: 0.6990\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 0s 148ms/step - loss: 0.6938 - val_loss: 0.6989\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 152ms/step - loss: 0.6916 - val_loss: 0.6989\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 153ms/step - loss: 0.6957 - val_loss: 0.6988\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 153ms/step - loss: 0.6914 - val_loss: 0.6988\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 151ms/step - loss: 0.6905 - val_loss: 0.6988\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 153ms/step - loss: 0.6918 - val_loss: 0.6989\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 0s 147ms/step - loss: 0.6975 - val_loss: 0.6990\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 146ms/step - loss: 0.6908 - val_loss: 0.6989\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 153ms/step - loss: 0.6915 - val_loss: 0.6989\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 147ms/step - loss: 0.6924 - val_loss: 0.6990\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 146ms/step - loss: 0.6898 - val_loss: 0.6991\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 0s 146ms/step - loss: 0.6959 - val_loss: 0.6992\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 0s 147ms/step - loss: 0.6919 - val_loss: 0.6992\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 153ms/step - loss: 0.6905 - val_loss: 0.6993\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 0s 147ms/step - loss: 0.6906 - val_loss: 0.6995\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 0s 146ms/step - loss: 0.6915 - val_loss: 0.6996\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.48      0.56        29\n",
            "         1.0       0.25      0.42      0.31        12\n",
            "\n",
            "    accuracy                           0.46        41\n",
            "   macro avg       0.46      0.45      0.44        41\n",
            "weighted avg       0.54      0.46      0.49        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.71      1.00      0.83        29\n",
            "         1.0       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.71        41\n",
            "   macro avg       0.35      0.50      0.41        41\n",
            "weighted avg       0.50      0.71      0.59        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        29\n",
            "         1.0       0.29      1.00      0.45        12\n",
            "\n",
            "    accuracy                           0.29        41\n",
            "   macro avg       0.15      0.50      0.23        41\n",
            "weighted avg       0.09      0.29      0.13        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        29\n",
            "         1.0       0.29      1.00      0.45        12\n",
            "\n",
            "    accuracy                           0.29        41\n",
            "   macro avg       0.15      0.50      0.23        41\n",
            "weighted avg       0.09      0.29      0.13        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.71      1.00      0.83        29\n",
            "         1.0       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.71        41\n",
            "   macro avg       0.35      0.50      0.41        41\n",
            "weighted avg       0.50      0.71      0.59        41\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2nD6KtJGria",
        "colab_type": "code",
        "outputId": "ff4c32a6-ddb3-4393-b440-bd82069a60c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Video\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class Highway(layers.Layer):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Highway, self).__init__()\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    n_sentences = input_shape[1]\n",
        "    n_features = input_shape[2]\n",
        "    carry_bias = keras.initializers.Constant(value=-1.0)\n",
        "    random_dist = keras.initializers.RandomNormal(mean=0.0, stddev=0.1)\n",
        "\n",
        "    carry_bias_2 = keras.initializers.Constant(value= 0.1)\n",
        "\n",
        "    self.W_T = self.add_weight(shape=(n_features, n_features),initializer = random_dist,trainable=True)\n",
        "    self.b_T = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias, trainable=True)\n",
        "    # self.W_T = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1),trainable=True)\n",
        "    # self.b_T = tf.Variable(tf.constant(-1.0, shape=[n_data_points, n_sentences, n_features]),trainable=True)\n",
        "   \n",
        "    self.W = self.add_weight(shape=( n_features, n_features),initializer = random_dist, trainable=True)\n",
        "    self.b = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias_2, trainable=True)\n",
        "    # self.W = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1), trainable=True)\n",
        "    # self.b = tf.Variable(tf.constant(0.1, shape=[n_data_points, n_sentences, n_features]), trainable=True)  \n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = inputs\n",
        "    T = tf.sigmoid(tf.matmul(x, self.W_T) + self.b_T, name=\"transform_gate\")\n",
        "    H = tf.nn.relu(tf.matmul(x, self.W) + self.b, name=\"activation\")\n",
        "    C = tf.subtract(1.0, T, name=\"carry_gate\")\n",
        "    \n",
        "    return tf.add(tf.multiply(H, T), tf.multiply(x, C), \"y\")\n",
        "\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "#LSTM FOR VIDEO\n",
        "# first input model\n",
        "\n",
        "input3 = Input(shape = (250,388))\n",
        "# dense4 = Dense(1000)(input3)\n",
        "# dense5 = Dense(500)(dense4)\n",
        "dense6 = Dense(250)(input3)\n",
        "# interpretation model\n",
        "lstm = LSTM(128, dropout = 0.2, recurrent_dropout = 0.2)(dense6)\n",
        "output = Dense(1, activation='sigmoid')(lstm)\n",
        "model = Model(inputs=input3, outputs=output)\n",
        "# summarize layers\n",
        "print(model.summary())\n",
        "# plot graph\n",
        "print(plot_model(model, to_file='multiple_inputs.png'))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0001)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
        "\n",
        "model.fit(video_train,Ytrain, validation_split = 0.2, callbacks = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=30, verbose=0, mode='min',\n",
        "    baseline=None, restore_best_weights=True), epochs=50, batch_size = 137)\n",
        "\n",
        "video_test = np.nan_to_num(video_test)\n",
        "\n",
        "def Thresholding(Y_pred, threshold):\n",
        "  Y_pred2 = []\n",
        "  print(\"Y_pred: \", Y_pred.shape)\n",
        "  for i in range(len(Y_pred)):\n",
        "    if(Y_pred[i] < threshold):\n",
        "      Y_pred2.append(0)\n",
        "    else:\n",
        "      Y_pred2.append(1)\n",
        "\n",
        "  return np.array(Y_pred2)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "pred = model.predict(video_test)\n",
        "\n",
        "print(classification_report(Ytest,Thresholding(pred,0.5)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.6)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.4)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.3)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.7)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 250, 388)]        0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 250, 250)          97250     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 128)               194048    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 291,427\n",
            "Trainable params: 291,427\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "<IPython.core.display.Image object>\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 1s 446ms/step - loss: 0.6941 - val_loss: 0.6937\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 1s 318ms/step - loss: 0.6941 - val_loss: 0.6945\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.6924 - val_loss: 0.6951\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 1s 316ms/step - loss: 0.7000 - val_loss: 0.6953\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 1s 314ms/step - loss: 0.6917 - val_loss: 0.6949\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 1s 317ms/step - loss: 0.6897 - val_loss: 0.6948\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 1s 317ms/step - loss: 0.6911 - val_loss: 0.6948\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 1s 320ms/step - loss: 0.6925 - val_loss: 0.6949\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.6905 - val_loss: 0.6950\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 1s 318ms/step - loss: 0.6892 - val_loss: 0.6952\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.6903 - val_loss: 0.6955\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 1s 320ms/step - loss: 0.6887 - val_loss: 0.6957\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 1s 314ms/step - loss: 0.6988 - val_loss: 0.6958\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 1s 320ms/step - loss: 0.6872 - val_loss: 0.6957\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 1s 315ms/step - loss: 0.6914 - val_loss: 0.6959\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 1s 316ms/step - loss: 0.6912 - val_loss: 0.6961\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.6883 - val_loss: 0.6964\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.6841 - val_loss: 0.6969\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.6983 - val_loss: 0.6974\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 1s 316ms/step - loss: 0.6784 - val_loss: 0.6979\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.6839 - val_loss: 0.6988\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 1s 319ms/step - loss: 0.6942 - val_loss: 0.6996\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 1s 319ms/step - loss: 0.7001 - val_loss: 0.6999\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 1s 321ms/step - loss: 0.7045 - val_loss: 0.6994\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.6916 - val_loss: 0.6984\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 1s 320ms/step - loss: 0.6895 - val_loss: 0.6976\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 1s 315ms/step - loss: 0.6886 - val_loss: 0.6971\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 1s 322ms/step - loss: 0.6969 - val_loss: 0.6966\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.6870 - val_loss: 0.6962\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.6873 - val_loss: 0.6961\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 1s 314ms/step - loss: 0.6898 - val_loss: 0.6962\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.70      0.97      0.81        29\n",
            "         1.0       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.68        41\n",
            "   macro avg       0.35      0.48      0.41        41\n",
            "weighted avg       0.50      0.68      0.57        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.71      1.00      0.83        29\n",
            "         1.0       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.71        41\n",
            "   macro avg       0.35      0.50      0.41        41\n",
            "weighted avg       0.50      0.71      0.59        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        29\n",
            "         1.0       0.29      1.00      0.45        12\n",
            "\n",
            "    accuracy                           0.29        41\n",
            "   macro avg       0.15      0.50      0.23        41\n",
            "weighted avg       0.09      0.29      0.13        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        29\n",
            "         1.0       0.29      1.00      0.45        12\n",
            "\n",
            "    accuracy                           0.29        41\n",
            "   macro avg       0.15      0.50      0.23        41\n",
            "weighted avg       0.09      0.29      0.13        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.71      1.00      0.83        29\n",
            "         1.0       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.71        41\n",
            "   macro avg       0.35      0.50      0.41        41\n",
            "weighted avg       0.50      0.71      0.59        41\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MjfyOh8EBGO",
        "colab_type": "code",
        "outputId": "cca17f52-41dd-4fb7-83d4-04b23feaef83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Text + Audio \n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class Highway(layers.Layer):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Highway, self).__init__()\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    n_sentences = input_shape[1]\n",
        "    n_features = input_shape[2]\n",
        "    carry_bias = keras.initializers.Constant(value=-1.0)\n",
        "    random_dist = keras.initializers.RandomNormal(mean=0.0, stddev=0.1)\n",
        "\n",
        "    carry_bias_2 = keras.initializers.Constant(value= 0.1)\n",
        "\n",
        "    self.W_T = self.add_weight(shape=(n_features, n_features),initializer = random_dist,trainable=True)\n",
        "    self.b_T = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias, trainable=True)\n",
        "    # self.W_T = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1),trainable=True)\n",
        "    # self.b_T = tf.Variable(tf.constant(-1.0, shape=[n_data_points, n_sentences, n_features]),trainable=True)\n",
        "   \n",
        "    self.W = self.add_weight(shape=( n_features, n_features),initializer = random_dist, trainable=True)\n",
        "    self.b = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias_2, trainable=True)\n",
        "    # self.W = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1), trainable=True)\n",
        "    # self.b = tf.Variable(tf.constant(0.1, shape=[n_data_points, n_sentences, n_features]), trainable=True)  \n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = inputs\n",
        "    T = tf.sigmoid(tf.matmul(x, self.W_T) + self.b_T, name=\"transform_gate\")\n",
        "    H = tf.nn.relu(tf.matmul(x, self.W) + self.b, name=\"activation\")\n",
        "    C = tf.subtract(1.0, T, name=\"carry_gate\")\n",
        "    \n",
        "    return tf.add(tf.multiply(H, T), tf.multiply(x, C), \"y\")\n",
        "\n",
        "\n",
        "# Multiple Inputs\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "# first input model\n",
        "input1 = Input(shape=(250,74), name = 'Audio_input')\n",
        "# highway1 = Highway()(input1)\n",
        "# highway5 = Highway()(highway1)\n",
        "# highway6 = Highway()(highway5)\n",
        "dense1 = Dense(74)(input1)\n",
        "\n",
        "# second input model\n",
        "# input2 = Input(shape=(250,388), name = 'Video_input')\n",
        "# highway2 = Highway()(input2)\n",
        "# highway3 = Highway()(highway2)\n",
        "# highway4 = Highway()(highway3)\n",
        "# dense7 = Dense(200)(highway4)\n",
        "# dense2 = Dense(74)(dense7)\n",
        "\n",
        "input3 = Input(shape = (250,5100), name = 'Text_input')\n",
        "dense4 = Dense(1000)(input3)\n",
        "dense5 = Dense(500)(dense4)\n",
        "dense6 = Dense(250)(dense5)\n",
        "dense3 = Dense(74)(dense6)\n",
        "# merge input models\n",
        "merge = concatenate([dense1,dense3], axis = 1)\n",
        "# interpretation model\n",
        "lstm = LSTM(128, dropout = 0.2, recurrent_dropout = 0.2)(merge)\n",
        "output = Dense(1, activation='sigmoid')(lstm)\n",
        "model = Model(inputs=[input1, input3], outputs=output)\n",
        "# summarize layers\n",
        "print(model.summary())\n",
        "# plot graph\n",
        "plot_model(model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0001)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
        "\n",
        "# inp = np.array([audio_train,video_train,text_train], dtype = object)\n",
        "\n",
        "filepath = '/content/drive/My Drive/MCA Dataset/checkFile.txt'\n",
        "model.fit([audio_train,text_train],Ytrain, validation_split = 0.2, callbacks = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=15, verbose=0, mode='min',\n",
        "    baseline=None, restore_best_weights=True),epochs=50, batch_size = 137)\n",
        "\n",
        "\n",
        "audio_test = np.nan_to_num(audio_test)\n",
        "video_test = np.nan_to_num(video_test)\n",
        "text_test = np.nan_to_num(text_test)\n",
        "\n",
        "\n",
        "for i in range(audio_test.shape[0]):\n",
        "  audio_test[i] = sklearn.preprocessing.normalize(audio_test[i])\n",
        "  video_test[i] = sklearn.preprocessing.normalize(video_test[i])\n",
        "  text_test[i] = sklearn.preprocessing.normalize(text_test[i])\n",
        "\n",
        "\n",
        "\n",
        "def Thresholding(Y_pred, threshold):\n",
        "  Y_pred2 = []\n",
        "  print(\"Y_pred: \", Y_pred.shape)\n",
        "  for i in range(len(Y_pred)):\n",
        "    if(Y_pred[i] < threshold):\n",
        "      Y_pred2.append(0)\n",
        "    else:\n",
        "      Y_pred2.append(1)\n",
        "\n",
        "  return np.array(Y_pred2)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "pred = model.predict([audio_test,text_test])\n",
        "pred2 = model.predict([audio_train,text_train])\n",
        "\n",
        "# num_arr = []\n",
        "# for i in range(0, len(pred)):\n",
        "#   num_arr.append(i)\n",
        "\n",
        "# # from matplotlib import pyplot as plt\n",
        "# # Y_pred = classifier.predict(finalMatrix_test)\n",
        "# plt.scatter(Y_pred, num_arr, c=Y_test)\n",
        "print(classification_report(Ytest,Thresholding(pred,0.5)))\n",
        "print(\"TRAINING ACCCCCC        \" , classification_report(Ytrain,Thresholding(pred2,0.5)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.6)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.4)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.3)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.7)))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Text_input (InputLayer)         [(None, 250, 5100)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 250, 1000)    5101000     Text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 250, 500)     500500      dense_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Audio_input (InputLayer)        [(None, 250, 74)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 250, 250)     125250      dense_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 250, 74)      5550        Audio_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 250, 74)      18574       dense_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 500, 74)      0           dense_20[0][0]                   \n",
            "                                                                 dense_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   (None, 128)          103936      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_25 (Dense)                (None, 1)            129         lstm_5[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 5,854,939\n",
            "Trainable params: 5,854,939\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6942 - val_loss: 0.6902\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6900 - val_loss: 0.6883\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6875 - val_loss: 0.6859\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6889 - val_loss: 0.6833\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6840 - val_loss: 0.6811\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6787 - val_loss: 0.6784\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6742 - val_loss: 0.6744\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6755 - val_loss: 0.6700\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6519 - val_loss: 0.6652\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6381 - val_loss: 0.6600\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6578 - val_loss: 0.6551\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6327 - val_loss: 0.6505\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6313 - val_loss: 0.6452\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6093 - val_loss: 0.6374\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6082 - val_loss: 0.6265\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6002 - val_loss: 0.6139\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6010 - val_loss: 0.6000\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.5458 - val_loss: 0.5846\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.5654 - val_loss: 0.5681\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.5161 - val_loss: 0.5505\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.5201 - val_loss: 0.5337\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.4998 - val_loss: 0.5189\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.4984 - val_loss: 0.5052\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3909 - val_loss: 0.4925\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.4485 - val_loss: 0.4877\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.4081 - val_loss: 0.4890\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.4984 - val_loss: 0.4797\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.4457 - val_loss: 0.4662\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.4271 - val_loss: 0.4610\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.4388 - val_loss: 0.4629\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3316 - val_loss: 0.4756\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3958 - val_loss: 0.4909\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.4078 - val_loss: 0.5019\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.4110 - val_loss: 0.4968\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3095 - val_loss: 0.4776\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3662 - val_loss: 0.4540\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3616 - val_loss: 0.4393\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.4581 - val_loss: 0.4362\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3657 - val_loss: 0.4388\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3392 - val_loss: 0.4462\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3803 - val_loss: 0.4503\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3734 - val_loss: 0.4536\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3336 - val_loss: 0.4633\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3544 - val_loss: 0.4723\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3651 - val_loss: 0.4721\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3875 - val_loss: 0.4621\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3258 - val_loss: 0.4478\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3974 - val_loss: 0.4428\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3530 - val_loss: 0.4414\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.4258 - val_loss: 0.4393\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.83      0.79        29\n",
            "         1.0       0.44      0.33      0.38        12\n",
            "\n",
            "    accuracy                           0.68        41\n",
            "   macro avg       0.60      0.58      0.58        41\n",
            "weighted avg       0.66      0.68      0.67        41\n",
            "\n",
            "Y_pred:  (196, 1)\n",
            "TRAINING ACCCCCC                       precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.68      1.00      0.81        98\n",
            "         1.0       1.00      0.52      0.68        98\n",
            "\n",
            "    accuracy                           0.76       196\n",
            "   macro avg       0.84      0.76      0.75       196\n",
            "weighted avg       0.84      0.76      0.75       196\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.83      0.79        29\n",
            "         1.0       0.44      0.33      0.38        12\n",
            "\n",
            "    accuracy                           0.68        41\n",
            "   macro avg       0.60      0.58      0.58        41\n",
            "weighted avg       0.66      0.68      0.67        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      0.38      0.50        29\n",
            "         1.0       0.31      0.67      0.42        12\n",
            "\n",
            "    accuracy                           0.46        41\n",
            "   macro avg       0.52      0.52      0.46        41\n",
            "weighted avg       0.61      0.46      0.48        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      0.38      0.50        29\n",
            "         1.0       0.31      0.67      0.42        12\n",
            "\n",
            "    accuracy                           0.46        41\n",
            "   macro avg       0.52      0.52      0.46        41\n",
            "weighted avg       0.61      0.46      0.48        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.83      0.79        29\n",
            "         1.0       0.44      0.33      0.38        12\n",
            "\n",
            "    accuracy                           0.68        41\n",
            "   macro avg       0.60      0.58      0.58        41\n",
            "weighted avg       0.66      0.68      0.67        41\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiJ8aIFLF1jG",
        "colab_type": "code",
        "outputId": "fd855133-6032-42cf-d682-52437dcb928e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Text+Video\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class Highway(layers.Layer):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Highway, self).__init__()\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    n_sentences = input_shape[1]\n",
        "    n_features = input_shape[2]\n",
        "    carry_bias = keras.initializers.Constant(value=-1.0)\n",
        "    random_dist = keras.initializers.RandomNormal(mean=0.0, stddev=0.1)\n",
        "\n",
        "    carry_bias_2 = keras.initializers.Constant(value= 0.1)\n",
        "\n",
        "    self.W_T = self.add_weight(shape=(n_features, n_features),initializer = random_dist,trainable=True)\n",
        "    self.b_T = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias, trainable=True)\n",
        "    # self.W_T = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1),trainable=True)\n",
        "    # self.b_T = tf.Variable(tf.constant(-1.0, shape=[n_data_points, n_sentences, n_features]),trainable=True)\n",
        "   \n",
        "    self.W = self.add_weight(shape=( n_features, n_features),initializer = random_dist, trainable=True)\n",
        "    self.b = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias_2, trainable=True)\n",
        "    # self.W = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1), trainable=True)\n",
        "    # self.b = tf.Variable(tf.constant(0.1, shape=[n_data_points, n_sentences, n_features]), trainable=True)  \n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = inputs\n",
        "    T = tf.sigmoid(tf.matmul(x, self.W_T) + self.b_T, name=\"transform_gate\")\n",
        "    H = tf.nn.relu(tf.matmul(x, self.W) + self.b, name=\"activation\")\n",
        "    C = tf.subtract(1.0, T, name=\"carry_gate\")\n",
        "    \n",
        "    return tf.add(tf.multiply(H, T), tf.multiply(x, C), \"y\")\n",
        "\n",
        "\n",
        "# Multiple Inputs\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "# first input model\n",
        "# input1 = Input(shape=(250,74), name = 'Audio_input')\n",
        "# highway1 = Highway()(input1)\n",
        "# highway5 = Highway()(highway1)\n",
        "# highway6 = Highway()(highway5)\n",
        "# dense1 = Dense(74)(highway6)\n",
        "\n",
        "# second input model\n",
        "input2 = Input(shape=(250,388), name = 'Video_input')\n",
        "# highway2 = Highway()(input2)\n",
        "# highway3 = Highway()(highway2)\n",
        "# highway4 = Highway()(highway3)\n",
        "# dense7 = Dense(200)(highway4)\n",
        "dense2 = Dense(250)(input2)\n",
        "\n",
        "input3 = Input(shape = (250,5100), name = 'Text_input')\n",
        "dense4 = Dense(1000)(input3)\n",
        "dense5 = Dense(500)(dense4)\n",
        "# dense6 = Dense(250)(dense5)\n",
        "dense3 = Dense(250)(dense5)\n",
        "# merge input models\n",
        "merge = concatenate([dense2,dense3], axis = 1)\n",
        "# interpretation model\n",
        "lstm = LSTM(128, dropout = 0.2, recurrent_dropout = 0.2)(merge)\n",
        "output = Dense(1, activation='sigmoid')(lstm)\n",
        "model = Model(inputs=[input2, input3], outputs=output)\n",
        "# summarize layers\n",
        "print(model.summary())\n",
        "# plot graph\n",
        "plot_model(model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0001)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
        "\n",
        "# inp = np.array([audio_train,video_train,text_train], dtype = object)\n",
        "\n",
        "filepath = '/content/drive/My Drive/MCA Dataset/checkFile.txt'\n",
        "model.fit([video_train,text_train],Ytrain, validation_split = 0.2, callbacks = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=15, verbose=0, mode='min',\n",
        "    baseline=None, restore_best_weights=True),epochs=50, batch_size = 137)\n",
        "\n",
        "\n",
        "audio_test = np.nan_to_num(audio_test)\n",
        "video_test = np.nan_to_num(video_test)\n",
        "text_test = np.nan_to_num(text_test)\n",
        "\n",
        "\n",
        "for i in range(audio_test.shape[0]):\n",
        "  audio_test[i] = sklearn.preprocessing.normalize(audio_test[i])\n",
        "  video_test[i] = sklearn.preprocessing.normalize(video_test[i])\n",
        "  text_test[i] = sklearn.preprocessing.normalize(text_test[i])\n",
        "\n",
        "\n",
        "\n",
        "def Thresholding(Y_pred, threshold):\n",
        "  Y_pred2 = []\n",
        "  print(\"Y_pred: \", Y_pred.shape)\n",
        "  for i in range(len(Y_pred)):\n",
        "    if(Y_pred[i] < threshold):\n",
        "      Y_pred2.append(0)\n",
        "    else:\n",
        "      Y_pred2.append(1)\n",
        "\n",
        "  return np.array(Y_pred2)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "pred = model.predict([video_test,text_test])\n",
        "pred2 = model.predict([video_train,text_train])\n",
        "\n",
        "# num_arr = []\n",
        "# for i in range(0, len(pred)):\n",
        "#   num_arr.append(i)\n",
        "\n",
        "# from matplotlib import pyplot as plt\n",
        "# Y_pred = classifier.predict(finalMatrix_test)\n",
        "# plt.scatter(Y_pred, num_arr, c=Y_test)\n",
        "print(classification_report(Ytest,Thresholding(pred,0.5)))\n",
        "print(\"TRAINING ACCCCCC        \" , classification_report(Ytrain,Thresholding(pred2,0.5)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.6)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.4)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.3)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.7)))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Text_input (InputLayer)         [(None, 250, 5100)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_31 (Dense)                (None, 250, 1000)    5101000     Text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "Video_input (InputLayer)        [(None, 250, 388)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_32 (Dense)                (None, 250, 500)     500500      dense_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_30 (Dense)                (None, 250, 250)     97250       Video_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_33 (Dense)                (None, 250, 250)     125250      dense_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 500, 250)     0           dense_30[0][0]                   \n",
            "                                                                 dense_33[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   (None, 128)          194048      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_34 (Dense)                (None, 1)            129         lstm_6[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 6,018,177\n",
            "Trainable params: 6,018,177\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6913 - val_loss: 0.6886\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6837 - val_loss: 0.6853\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6797 - val_loss: 0.6818\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6706 - val_loss: 0.6785\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6638 - val_loss: 0.6754\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6600 - val_loss: 0.6726\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6964 - val_loss: 0.6703\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6782 - val_loss: 0.6675\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6559 - val_loss: 0.6641\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6399 - val_loss: 0.6600\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6602 - val_loss: 0.6551\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6434 - val_loss: 0.6498\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6370 - val_loss: 0.6444\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6253 - val_loss: 0.6384\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6169 - val_loss: 0.6319\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.5956 - val_loss: 0.6238\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.5538 - val_loss: 0.6137\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6199 - val_loss: 0.6016\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.5723 - val_loss: 0.5879\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.5631 - val_loss: 0.5736\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.5545 - val_loss: 0.5593\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4892 - val_loss: 0.5453\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.5091 - val_loss: 0.5312\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.5303 - val_loss: 0.5172\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4964 - val_loss: 0.5051\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.5010 - val_loss: 0.4981\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4386 - val_loss: 0.5013\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.5041 - val_loss: 0.5049\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4279 - val_loss: 0.5035\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4234 - val_loss: 0.5006\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4127 - val_loss: 0.4947\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4530 - val_loss: 0.4900\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4482 - val_loss: 0.4892\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3990 - val_loss: 0.4917\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4049 - val_loss: 0.4940\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3796 - val_loss: 0.4883\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3538 - val_loss: 0.4792\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3946 - val_loss: 0.4682\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3445 - val_loss: 0.4553\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3098 - val_loss: 0.4439\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3326 - val_loss: 0.4376\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3151 - val_loss: 0.4353\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4428 - val_loss: 0.4356\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4072 - val_loss: 0.4502\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3510 - val_loss: 0.4822\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3417 - val_loss: 0.4972\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3844 - val_loss: 0.4866\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3661 - val_loss: 0.4754\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3789 - val_loss: 0.4710\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3762 - val_loss: 0.4666\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      0.38      0.50        29\n",
            "         1.0       0.31      0.67      0.42        12\n",
            "\n",
            "    accuracy                           0.46        41\n",
            "   macro avg       0.52      0.52      0.46        41\n",
            "weighted avg       0.61      0.46      0.48        41\n",
            "\n",
            "Y_pred:  (196, 1)\n",
            "TRAINING ACCCCCC                       precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.94      0.52      0.67        98\n",
            "         1.0       0.67      0.97      0.79        98\n",
            "\n",
            "    accuracy                           0.74       196\n",
            "   macro avg       0.81      0.74      0.73       196\n",
            "weighted avg       0.81      0.74      0.73       196\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.83      0.79        29\n",
            "         1.0       0.44      0.33      0.38        12\n",
            "\n",
            "    accuracy                           0.68        41\n",
            "   macro avg       0.60      0.58      0.58        41\n",
            "weighted avg       0.66      0.68      0.67        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      0.38      0.50        29\n",
            "         1.0       0.31      0.67      0.42        12\n",
            "\n",
            "    accuracy                           0.46        41\n",
            "   macro avg       0.52      0.52      0.46        41\n",
            "weighted avg       0.61      0.46      0.48        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      0.38      0.50        29\n",
            "         1.0       0.31      0.67      0.42        12\n",
            "\n",
            "    accuracy                           0.46        41\n",
            "   macro avg       0.52      0.52      0.46        41\n",
            "weighted avg       0.61      0.46      0.48        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.83      0.79        29\n",
            "         1.0       0.44      0.33      0.38        12\n",
            "\n",
            "    accuracy                           0.68        41\n",
            "   macro avg       0.60      0.58      0.58        41\n",
            "weighted avg       0.66      0.68      0.67        41\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOeZhMQDGF6s",
        "colab_type": "code",
        "outputId": "92fb7284-5224-4dfa-f393-9fa264fe2b6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Text+Audio+Video\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class Highway(layers.Layer):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Highway, self).__init__()\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    n_sentences = input_shape[1]\n",
        "    n_features = input_shape[2]\n",
        "    carry_bias = keras.initializers.Constant(value=-1.0)\n",
        "    random_dist = keras.initializers.RandomNormal(mean=0.0, stddev=0.1)\n",
        "\n",
        "    carry_bias_2 = keras.initializers.Constant(value= 0.1)\n",
        "\n",
        "    self.W_T = self.add_weight(shape=(n_features, n_features),initializer = random_dist,trainable=True)\n",
        "    self.b_T = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias, trainable=True)\n",
        "    # self.W_T = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1),trainable=True)\n",
        "    # self.b_T = tf.Variable(tf.constant(-1.0, shape=[n_data_points, n_sentences, n_features]),trainable=True)\n",
        "   \n",
        "    self.W = self.add_weight(shape=( n_features, n_features),initializer = random_dist, trainable=True)\n",
        "    self.b = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias_2, trainable=True)\n",
        "    # self.W = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1), trainable=True)\n",
        "    # self.b = tf.Variable(tf.constant(0.1, shape=[n_data_points, n_sentences, n_features]), trainable=True)  \n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = inputs\n",
        "    T = tf.sigmoid(tf.matmul(x, self.W_T) + self.b_T, name=\"transform_gate\")\n",
        "    H = tf.nn.relu(tf.matmul(x, self.W) + self.b, name=\"activation\")\n",
        "    C = tf.subtract(1.0, T, name=\"carry_gate\")\n",
        "    \n",
        "    return tf.add(tf.multiply(H, T), tf.multiply(x, C), \"y\")\n",
        "\n",
        "\n",
        "# Multiple Inputs\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "# first input model\n",
        "input1 = Input(shape=(250,74), name = 'Audio_input')\n",
        "# highway1 = Highway()(input1)\n",
        "# highway5 = Highway()(highway1)\n",
        "# highway6 = Highway()(highway5)\n",
        "dense1 = Dense(74)(input1)\n",
        "\n",
        "# second input model\n",
        "input2 = Input(shape=(250,388), name = 'Video_input')\n",
        "# highway2 = Highway()(input2)\n",
        "# highway3 = Highway()(highway2)\n",
        "# highway4 = Highway()(highway3)\n",
        "dense7 = Dense(200)(input2)\n",
        "dense2 = Dense(74)(dense7)\n",
        "\n",
        "input3 = Input(shape = (250,5100), name = 'Text_input')\n",
        "dense4 = Dense(1000)(input3)\n",
        "dense5 = Dense(500)(dense4)\n",
        "dense6 = Dense(250)(dense5)\n",
        "dense3 = Dense(74)(dense6)\n",
        "# merge input models\n",
        "merge = concatenate([dense1,dense2,dense3], axis = 1)\n",
        "# interpretation model\n",
        "lstm = LSTM(128, dropout = 0.2, recurrent_dropout = 0.2)(merge)\n",
        "output = Dense(1, activation='sigmoid')(lstm)\n",
        "model = Model(inputs=[input1, input2, input3], outputs=output)\n",
        "# summarize layers\n",
        "print(model.summary())\n",
        "# plot graph\n",
        "plot_model(model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0001)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
        "\n",
        "# inp = np.array([audio_train,video_train,text_train], dtype = object)\n",
        "\n",
        "filepath = '/content/drive/My Drive/MCA Dataset/checkFile.txt'\n",
        "model.fit([audio_train,video_train,text_train],Ytrain, validation_split = 0.2, callbacks = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=15, verbose=0, mode='min',\n",
        "    baseline=None, restore_best_weights=True),epochs=50, batch_size = 137)\n",
        "\n",
        "\n",
        "audio_test = np.nan_to_num(audio_test)\n",
        "video_test = np.nan_to_num(video_test)\n",
        "text_test = np.nan_to_num(text_test)\n",
        "\n",
        "\n",
        "for i in range(audio_test.shape[0]):\n",
        "  audio_test[i] = sklearn.preprocessing.normalize(audio_test[i])\n",
        "  video_test[i] = sklearn.preprocessing.normalize(video_test[i])\n",
        "  text_test[i] = sklearn.preprocessing.normalize(text_test[i])\n",
        "\n",
        "\n",
        "\n",
        "def Thresholding(Y_pred, threshold):\n",
        "  Y_pred2 = []\n",
        "  print(\"Y_pred: \", Y_pred.shape)\n",
        "  for i in range(len(Y_pred)):\n",
        "    if(Y_pred[i] < threshold):\n",
        "      Y_pred2.append(0)\n",
        "    else:\n",
        "      Y_pred2.append(1)\n",
        "\n",
        "  return np.array(Y_pred2)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "pred = model.predict([audio_test,video_test,text_test])\n",
        "pred2 = model.predict([audio_train,video_train,text_train])\n",
        "\n",
        "# num_arr = []\n",
        "# for i in range(0, len(pred)):\n",
        "#   num_arr.append(i)\n",
        "\n",
        "# from matplotlib import pyplot as plt\n",
        "# Y_pred = classifier.predict(finalMatrix_test)\n",
        "# plt.scatter(Y_pred, num_arr, c=Y_test)\n",
        "print(classification_report(Ytest,Thresholding(pred,0.5)))\n",
        "print(\"TRAINING ACCCCCC        \" , classification_report(Ytrain,Thresholding(pred2,0.5)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.6)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.4)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.3)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.7)))\n",
        "\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Text_input (InputLayer)         [(None, 250, 5100)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_38 (Dense)                (None, 250, 1000)    5101000     Text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "Video_input (InputLayer)        [(None, 250, 388)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_39 (Dense)                (None, 250, 500)     500500      dense_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Audio_input (InputLayer)        [(None, 250, 74)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_36 (Dense)                (None, 250, 200)     77800       Video_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_40 (Dense)                (None, 250, 250)     125250      dense_39[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_35 (Dense)                (None, 250, 74)      5550        Audio_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_37 (Dense)                (None, 250, 74)      14874       dense_36[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_41 (Dense)                (None, 250, 74)      18574       dense_40[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 750, 74)      0           dense_35[0][0]                   \n",
            "                                                                 dense_37[0][0]                   \n",
            "                                                                 dense_41[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   (None, 128)          103936      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_42 (Dense)                (None, 1)            129         lstm_7[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 5,947,613\n",
            "Trainable params: 5,947,613\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 4s 2s/step - loss: 0.6936 - val_loss: 0.6911\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6884 - val_loss: 0.6884\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6872 - val_loss: 0.6858\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6858 - val_loss: 0.6834\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6795 - val_loss: 0.6810\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6852 - val_loss: 0.6785\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6783 - val_loss: 0.6756\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6604 - val_loss: 0.6724\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6418 - val_loss: 0.6680\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6555 - val_loss: 0.6622\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6367 - val_loss: 0.6557\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6290 - val_loss: 0.6483\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6274 - val_loss: 0.6397\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.6149 - val_loss: 0.6299\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.5830 - val_loss: 0.6185\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.5764 - val_loss: 0.6061\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.5803 - val_loss: 0.5925\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.5886 - val_loss: 0.5784\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.5075 - val_loss: 0.5633\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.5096 - val_loss: 0.5465\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4956 - val_loss: 0.5321\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4763 - val_loss: 0.5245\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4650 - val_loss: 0.5076\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4536 - val_loss: 0.4857\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3948 - val_loss: 0.4736\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3825 - val_loss: 0.4646\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3764 - val_loss: 0.4552\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4181 - val_loss: 0.4543\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4360 - val_loss: 0.4808\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3536 - val_loss: 0.5077\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4372 - val_loss: 0.4958\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4277 - val_loss: 0.4810\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3419 - val_loss: 0.4688\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3364 - val_loss: 0.4597\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3692 - val_loss: 0.4598\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3471 - val_loss: 0.4586\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3717 - val_loss: 0.4494\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3385 - val_loss: 0.4472\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3653 - val_loss: 0.4577\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3907 - val_loss: 0.4565\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3720 - val_loss: 0.4345\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3996 - val_loss: 0.4243\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3402 - val_loss: 0.4231\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3451 - val_loss: 0.4241\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3792 - val_loss: 0.4307\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3871 - val_loss: 0.4559\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3394 - val_loss: 0.4930\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3319 - val_loss: 0.4853\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3460 - val_loss: 0.4633\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3595 - val_loss: 0.4519\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.41      0.53        29\n",
            "         1.0       0.32      0.67      0.43        12\n",
            "\n",
            "    accuracy                           0.49        41\n",
            "   macro avg       0.54      0.54      0.48        41\n",
            "weighted avg       0.62      0.49      0.50        41\n",
            "\n",
            "Y_pred:  (196, 1)\n",
            "TRAINING ACCCCCC                       precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.59      0.69        98\n",
            "         1.0       0.69      0.89      0.77        98\n",
            "\n",
            "    accuracy                           0.74       196\n",
            "   macro avg       0.76      0.74      0.73       196\n",
            "weighted avg       0.76      0.74      0.73       196\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.83      0.79        29\n",
            "         1.0       0.44      0.33      0.38        12\n",
            "\n",
            "    accuracy                           0.68        41\n",
            "   macro avg       0.60      0.58      0.58        41\n",
            "weighted avg       0.66      0.68      0.67        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      0.38      0.50        29\n",
            "         1.0       0.31      0.67      0.42        12\n",
            "\n",
            "    accuracy                           0.46        41\n",
            "   macro avg       0.52      0.52      0.46        41\n",
            "weighted avg       0.61      0.46      0.48        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      0.38      0.50        29\n",
            "         1.0       0.31      0.67      0.42        12\n",
            "\n",
            "    accuracy                           0.46        41\n",
            "   macro avg       0.52      0.52      0.46        41\n",
            "weighted avg       0.61      0.46      0.48        41\n",
            "\n",
            "Y_pred:  (41, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.83      0.79        29\n",
            "         1.0       0.44      0.33      0.38        12\n",
            "\n",
            "    accuracy                           0.68        41\n",
            "   macro avg       0.60      0.58      0.58        41\n",
            "weighted avg       0.66      0.68      0.67        41\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
