{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_ MCA_Video.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/notmanan/Depression-Detection-Through-Multi-Modal-Data/blob/master/CNN__MCA_Video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncPer7MulwaY",
        "colab_type": "text"
      },
      "source": [
        "**Connecting Drive to Google Colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FkprWXdn7N3",
        "colab_type": "code",
        "outputId": "7507d3f9-de0d-44bd-b4c2-5e64634d4e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9ZapOLwl70D",
        "colab_type": "text"
      },
      "source": [
        "**Loading, Data Preprocessing for video**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzxb5JsroQ5y",
        "colab_type": "code",
        "outputId": "529c282d-a284-49f3-f0c8-4b5c4f986500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def processData(data):\n",
        "    # print(data)\n",
        "    X = data.iloc[:,:].values\n",
        "    X = np.delete(X, 0, 1)\n",
        "    X = np.delete(X, 1, 1)\n",
        "    for i in range(len(X)):\n",
        "        if(isinstance(X[i][5],str) or isinstance(X[i][7],str)):\n",
        "            X[i] = np.zeros((1, X.shape[1]))\n",
        "            print(\"string error\")\n",
        "    return X\n",
        "\n",
        "def getData(filename):\n",
        "    data = pd.read_csv(filename,delimiter=',', engine='python')\n",
        "    X = processData(data)\n",
        "    return X\n",
        "\n",
        "def makeDataPoint(patientNo):\n",
        "    file1 = (patientNo)+\"_CLNF_AUs.txt\"\n",
        "    file2 = (patientNo)+\"_CLNF_features.txt\"\n",
        "    file3 = (patientNo)+\"_CLNF_features3D.txt\"\n",
        "    file4 = (patientNo)+\"_CLNF_gaze.txt\"\n",
        "    file5 = (patientNo)+\"_CLNF_hog.txt\"\n",
        "    file6 = (patientNo)+\"_CLNF_pose.txt\"\n",
        "\n",
        "    X1 = getData(file1)\n",
        "    X2 = getData(file2)\n",
        "    X3 = getData(file3)\n",
        "    X4 = getData(file4)\n",
        "    X6 = getData(file6)\n",
        "\n",
        "    X = np.concatenate((X1, X2, X3, X4, X6), 1)\n",
        "    return X\n",
        "\n",
        "def scale_down(X):\n",
        "  X_new = []\n",
        "  size = 2\n",
        "  for i in range(int(X.shape[0]/size)):\n",
        "    cur_row = X[i*size]\n",
        "    for j in range(1,size):\n",
        "      if(i+j < X.shape[0]):\n",
        "        cur_row += X[i+j]\n",
        "    cur_row = cur_row/size\n",
        "    X_new.append(cur_row)\n",
        "  X_new = np.array(X_new)\n",
        "  return X_new\n",
        "\n",
        "# def decrease_size(X):\n",
        "#   size = 10000\n",
        "#   print(\"Size: \" + str(X.shape[0]))\n",
        "#   if(X.shape[0]<size):\n",
        "#     dif = size - X.shape[0] \n",
        "#     temp = np.zeros((dif,X.shape[1]))\n",
        "#     X = np.concatenate((X,temp),axis = 0)\n",
        "#   if(X.shape[0]>size):\n",
        "#     dif = X.shape[0] - size\n",
        "#     while(dif>0):\n",
        "#       index = np.random.randint(0,X.shape[0]-1)\n",
        "#       for i in range(X.shape[1]):\n",
        "#         X[index][i] = (X[index][i] + X[index+1][i])/2\n",
        "#       X = np.delete(X,index+1,axis = 0)\n",
        "#       dif = X.shape[0] - size\n",
        "#   return X\n",
        "\n",
        "def decrease_size(X):\n",
        "  size = 10000\n",
        "  print(\"Size: \" + str(X.shape[0]))\n",
        "  if(X.shape[0] < size):\n",
        "    dif = size - X.shape[0] \n",
        "    temp = np.zeros((dif,X.shape[1]))\n",
        "    X = np.concatenate((X,temp),axis = 0)\n",
        "  elif(X.shape[0] > size):\n",
        "    X = X[:10000, :]\n",
        "    print(\"New Shape\" + str(X.shape[0]))\n",
        "  return X\n",
        "\n",
        "def makeDataset(location, folder):\n",
        "    file  = np.array(pd.read_csv(location,delimiter=',',encoding='utf-8'))[:, 0:2]\n",
        "    X_temp = []\n",
        "    Y_temp = []\n",
        "    for i in range(len(file)):\n",
        "      patientID = (str(int(file[i][0])))\n",
        "      print(patientID)\n",
        "      string = '/content/drive/My Drive/MCA Dataset/' + folder +\"/\"+ patientID\n",
        "      XT = makeDataPoint(string)\n",
        "      XT = scale_down(XT)\n",
        "      XT = decrease_size(XT)\n",
        "      X_temp.append(XT)\n",
        "      Y_temp.append(int(file[i][1]))\n",
        "    Y_temp = np.asarray(Y_temp)\n",
        "    return X_temp, Y_temp\n",
        "\n",
        "print(\"train\")\n",
        "X_train, Y_train = makeDataset('/content/drive/My Drive/MCA Dataset/train_split_Depression_AVEC2017.csv', 'train_data')\n",
        "\n",
        "print(\"dev\")\n",
        "X_dev, Y_dev = makeDataset('/content/drive/My Drive/MCA Dataset/dev_split_Depression_AVEC2017.csv', 'dev_data')\n",
        "\n",
        "print(\"test\")\n",
        "X_test, Y_test = makeDataset('/content/drive/My Drive/MCA Dataset/full_test_split.csv', 'test_data')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "303\n",
            "Size: 14782\n",
            "New Shape10000\n",
            "304\n",
            "Size: 11890\n",
            "New Shape10000\n",
            "305\n",
            "Size: 25561\n",
            "New Shape10000\n",
            "310\n",
            "Size: 12804\n",
            "New Shape10000\n",
            "312\n",
            "Size: 11972\n",
            "New Shape10000\n",
            "313\n",
            "Size: 11424\n",
            "New Shape10000\n",
            "315\n",
            "Size: 14780\n",
            "New Shape10000\n",
            "316\n",
            "Size: 13168\n",
            "New Shape10000\n",
            "317\n",
            "Size: 12197\n",
            "New Shape10000\n",
            "318\n",
            "Size: 8916\n",
            "319\n",
            "Size: 10301\n",
            "New Shape10000\n",
            "320\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-92e424bee8aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0mX_trainaa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_trainaa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakeDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/MCA Dataset/train_split_Depression_AVEC2017.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m# print(\"dev\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-92e424bee8aa>\u001b[0m in \u001b[0;36mmakeDataset\u001b[0;34m(location, folder)\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatientID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/MCA Dataset/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mpatientID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0mXT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakeDataPoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m       \u001b[0mXT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_down\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m       \u001b[0mXT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecrease_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-92e424bee8aa>\u001b[0m in \u001b[0;36mmakeDataPoint\u001b[0;34m(patientNo)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mX1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mX3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mX4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-92e424bee8aa>\u001b[0m in \u001b[0;36mgetData\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m   2497\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_date_conversions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2499\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2500\u001b[0m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malldata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexnamerow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_convert_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2568\u001b[0m             \u001b[0mclean_conv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2569\u001b[0;31m             \u001b[0mclean_dtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2570\u001b[0m         )\n\u001b[1;32m   2571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_convert_to_ndarrays\u001b[0;34m(self, dct, na_values, na_fvalues, verbose, converters, dtypes)\u001b[0m\n\u001b[1;32m   1734\u001b[0m                 \u001b[0;31m# general type inference and conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m                 cvals, na_count = self._infer_types(\n\u001b[0;32m-> 1736\u001b[0;31m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_na_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mcol_na_fvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_num_bool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m                 )\n\u001b[1;32m   1738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_infer_types\u001b[0;34m(self, values, na_values, try_num_bool)\u001b[0m\n\u001b[1;32m   1794\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_num_bool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1796\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_convert_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1797\u001b[0m                 \u001b[0mna_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd-ptnEWNFan",
        "colab_type": "code",
        "outputId": "b28b4480-6c08-4142-88d8-68dec202097a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# print(len(X_train))\n",
        "# print(len(X_train[0]))\n",
        "# print(len(X_dev))\n",
        "# print(len(X_dev[0]))\n",
        "# for i in X_train:\n",
        "# print(len(np.array(pd.read_csv('/content/drive/My Drive/MCA Dataset/train_split_Depression_AVEC2017.csv', delimiter= ' ', encoding = 'utf-8'))[:, 0:2]))\n",
        "\n",
        "#   print(i)\n",
        "# X_traina = X_train\n",
        "# X_train = X_train[:103]\n",
        "# print(len(X_train)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "padperlL6-ri",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**RF and SVM on dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClUVyIzMXre8",
        "colab_type": "code",
        "outputId": "199ece95-f101-4e98-c75a-c55a599f65ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "YtrainTotal = np.concatenate((Y_train, Y_dev))\n",
        "XtrainTotal = X_train + X_dev \n",
        "XtrainTotal = np.asarray(XtrainTotal, dtype=np.float32)\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Step 1 - Convolution\n",
        "classifier.add(Conv1D(300, 3, input_shape = (10000, 388), activation = 'relu'))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling1D(pool_size = 2))\n",
        "\n",
        "classifier.add(Conv1D(150, 3, activation = 'relu'))\n",
        "classifier.add(MaxPooling1D(pool_size = 2))\n",
        "\n",
        "# Adding a second convolutional layer\n",
        "classifier.add(Conv1D(75, 3, activation = 'relu'))\n",
        "classifier.add(MaxPooling1D(pool_size = 2))\n",
        "\n",
        "classifier.add(Conv1D(32, 3, activation = 'relu'))\n",
        "classifier.add(MaxPooling1D(pool_size = 2))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "from keras import metrics\n",
        "\n",
        "# Compiling the CNN\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n",
        "class_weight = { 0: 0.3, 1:0.7}\n",
        "classifier.fit(XtrainTotal, YtrainTotal, epochs=5)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "137/137 [==============================] - 31s 223ms/step - loss: 11.2879\n",
            "Epoch 2/5\n",
            "137/137 [==============================] - 29s 211ms/step - loss: 11.4040\n",
            "Epoch 3/5\n",
            "137/137 [==============================] - 29s 212ms/step - loss: 11.4040\n",
            "Epoch 4/5\n",
            "137/137 [==============================] - 29s 212ms/step - loss: 11.4040\n",
            "Epoch 5/5\n",
            "137/137 [==============================] - 29s 213ms/step - loss: 11.4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9aa660d7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0icBYu3bRF7",
        "colab_type": "code",
        "outputId": "0beb946a-cdea-4d31-ca29-fcad12482630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# score = classifier.evaluate(X_test, Y_test)\n",
        "from sklearn.metrics import classification_report\n",
        "# print(classification_report(Y_test,classifier.predict(np.asarray(X_test))))\n",
        "print(\"On Training Set: \")\n",
        "print(classification_report(YtrainTotal,classifier.predict(np.asarray(XtrainTotal))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On Training Set: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        98\n",
            "           1       0.28      1.00      0.44        39\n",
            "\n",
            "    accuracy                           0.28       137\n",
            "   macro avg       0.14      0.50      0.22       137\n",
            "weighted avg       0.08      0.28      0.13       137\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omJfxEneA838",
        "colab_type": "code",
        "outputId": "9eff0ce9-82e2-4ade-f029-5d7945d0bb8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(classifier.predict(np.asarray(XtrainTotal)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}