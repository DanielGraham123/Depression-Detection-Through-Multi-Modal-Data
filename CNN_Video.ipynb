{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_ MCA_Video.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/notmanan/Depression-Detection-Through-Multi-Modal-Data/blob/master/CNN__MCA_Video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncPer7MulwaY",
        "colab_type": "text"
      },
      "source": [
        "**Connecting Drive to Google Colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FkprWXdn7N3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9ZapOLwl70D",
        "colab_type": "text"
      },
      "source": [
        "**Loading, Data Preprocessing for video**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzxb5JsroQ5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def processData(data):\n",
        "    # print(data)\n",
        "    X = data.iloc[:,:].values\n",
        "    X = np.delete(X, 0, 1)\n",
        "    X = np.delete(X, 1, 1)\n",
        "    for i in range(len(X)):\n",
        "        if(isinstance(X[i][5],str) or isinstance(X[i][7],str)):\n",
        "            X[i] = np.zeros((1, X.shape[1]))\n",
        "            print(\"se\" , end = \" \")\n",
        "    return X\n",
        "\n",
        "def getData(filename):\n",
        "    data = pd.read_csv(filename,delimiter=',', engine='python')\n",
        "    X = processData(data)\n",
        "    return X\n",
        "\n",
        "def makeDataPoint(patientNo):\n",
        "    file1 = (patientNo)+\"_CLNF_AUs.txt\"\n",
        "    file2 = (patientNo)+\"_CLNF_features.txt\"\n",
        "    file3 = (patientNo)+\"_CLNF_features3D.txt\"\n",
        "    file4 = (patientNo)+\"_CLNF_gaze.txt\"\n",
        "    file5 = (patientNo)+\"_CLNF_hog.txt\"\n",
        "    file6 = (patientNo)+\"_CLNF_pose.txt\"\n",
        "\n",
        "    X1 = getData(file1)\n",
        "    X2 = getData(file2)\n",
        "    X3 = getData(file3)\n",
        "    X4 = getData(file4)\n",
        "    X6 = getData(file6)\n",
        "\n",
        "    X = np.concatenate((X1, X2, X3, X4, X6), 1)\n",
        "    return X\n",
        "\n",
        "def scale_down(X):\n",
        "  X_new = []\n",
        "  size = 2\n",
        "  for i in range(int(X.shape[0]/size)):\n",
        "    cur_row = X[i*size]\n",
        "    for j in range(1,size):\n",
        "      if(i+j < X.shape[0]):\n",
        "        cur_row += X[i+j]\n",
        "    cur_row = cur_row/size\n",
        "    X_new.append(cur_row)\n",
        "  X_new = np.array(X_new)\n",
        "  return X_new\n",
        "\n",
        "# def decrease_size(X):\n",
        "#   size = 10000\n",
        "#   print(\"Size: \" + str(X.shape[0]))\n",
        "#   if(X.shape[0]<size):\n",
        "#     dif = size - X.shape[0] \n",
        "#     temp = np.zeros((dif,X.shape[1]))\n",
        "#     X = np.concatenate((X,temp),axis = 0)\n",
        "#   if(X.shape[0]>size):\n",
        "#     dif = X.shape[0] - size\n",
        "#     while(dif>0):\n",
        "#       index = np.random.randint(0,X.shape[0]-1)\n",
        "#       for i in range(X.shape[1]):\n",
        "#         X[index][i] = (X[index][i] + X[index+1][i])/2\n",
        "#       X = np.delete(X,index+1,axis = 0)\n",
        "#       dif = X.shape[0] - size\n",
        "#   return X\n",
        "\n",
        "def decrease_size(X):\n",
        "  size = 10000\n",
        "  # print(\"Size: \" + str(X.shape[0]))\n",
        "  if(X.shape[0] < size):\n",
        "    dif = size - X.shape[0] \n",
        "    temp = np.zeros((dif,X.shape[1]))\n",
        "    X = np.concatenate((X,temp),axis = 0)\n",
        "  elif(X.shape[0] > size):\n",
        "    X = X[:10000, :]\n",
        "    # print(\"New Shape\" + str(X.shape[0]))\n",
        "  return X\n",
        "\n",
        "def makeDataset(location, folder):\n",
        "    file  = np.array(pd.read_csv(location,delimiter=',',encoding='utf-8'))[:, 0:2]\n",
        "    X_temp = []\n",
        "    Y_temp = []\n",
        "    for i in range(len(file)):\n",
        "      patientID = (str(int(file[i][0])))\n",
        "      print(patientID)\n",
        "      string = '/content/drive/My Drive/MCA Dataset/' + folder +\"/\"+ patientID\n",
        "      XT = makeDataPoint(string)\n",
        "      XT = scale_down(XT)\n",
        "      XT = decrease_size(XT)\n",
        "      X_temp.append(XT)\n",
        "      Y_temp.append(int(file[i][1]))\n",
        "    Y_temp = np.asarray(Y_temp)\n",
        "    return X_temp, Y_temp\n",
        "\n",
        "print(\"train\")\n",
        "X_train, Y_train = makeDataset('/content/drive/My Drive/MCA Dataset/train_split_Depression_AVEC2017.csv', 'train_data')\n",
        "\n",
        "print(\"dev\")\n",
        "X_dev, Y_dev = makeDataset('/content/drive/My Drive/MCA Dataset/dev_split_Depression_AVEC2017.csv', 'dev_data')\n",
        "\n",
        "print(\"test\")\n",
        "X_test, Y_test = makeDataset('/content/drive/My Drive/MCA Dataset/full_test_split.csv', 'test_data')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "padperlL6-ri",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**CNN on dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClUVyIzMXre8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "YtrainTotal = np.concatenate((Y_train, Y_dev))\n",
        "XtrainTotal = X_train + X_dev \n",
        "XtrainTotal = np.asarray(XtrainTotal, dtype=np.float32)\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Step 1 - Convolution\n",
        "classifier.add(Conv1D(300, 3, input_shape = (10000, 388), activation = 'relu'))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling1D(pool_size = 2))\n",
        "\n",
        "classifier.add(Conv1D(150, 3, activation = 'relu'))\n",
        "classifier.add(MaxPooling1D(pool_size = 2))\n",
        "\n",
        "# Adding a second convolutional layer\n",
        "classifier.add(Conv1D(75, 3, activation = 'relu'))\n",
        "classifier.add(MaxPooling1D(pool_size = 2))\n",
        "\n",
        "classifier.add(Conv1D(32, 3, activation = 'relu'))\n",
        "classifier.add(MaxPooling1D(pool_size = 2))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "from keras import metrics\n",
        "\n",
        "# Compiling the CNN\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n",
        "class_weight = { 0: 0.3, 1:0.7}\n",
        "classifier.fit(XtrainTotal, YtrainTotal, epochs=5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0icBYu3bRF7",
        "colab_type": "code",
        "outputId": "d5760196-6983-4832-ee66-394fe1c75103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "# score = classifier.evaluate(X_test, Y_test)\n",
        "from sklearn.metrics import classification_report\n",
        "# print(classification_report(Y_test,classifier.predict(np.asarray(X_test))))\n",
        "print(\"On Test Set: \")\n",
        "print(classification_report(Y_test,classifier.predict(np.asarray(X_test))))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On Test Set: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        29\n",
            "           1       0.29      1.00      0.45        12\n",
            "\n",
            "    accuracy                           0.29        41\n",
            "   macro avg       0.15      0.50      0.23        41\n",
            "weighted avg       0.09      0.29      0.13        41\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omJfxEneA838",
        "colab_type": "code",
        "outputId": "00458b2d-5d6f-4ab8-a14c-862716839d3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        }
      },
      "source": [
        "print(classifier.predict(np.asarray(X_test)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
